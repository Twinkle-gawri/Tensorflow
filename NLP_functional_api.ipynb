{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM3FheMJ5e03l/yq7NJbsUe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Twinkle-gawri/Tensorflow/blob/main/NLP_functional_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9rCrnTgf-xt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()   # initially hi yeh train and test me divided hote h"
      ],
      "metadata": {
        "id": "malcAibiiG5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d53f82e-8f61-457e-8979-4cc736466dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_mD5nPwqBwY",
        "outputId": "7ca14014-223b-47c3-f7f0-844c89801ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Convert 2D Images into 1D Vectors\n",
        "* The original shape of the images is (28, 28), which is a 2D array.\n",
        "* Neural networks, especially dense (fully connected) layers, typically expect the input as 1D vectors.\n",
        "* Therefore, the images need to be flattened into a shape of 28×28 = 784 (1D vector) for processing.\n",
        "* Example:\n",
        "Original image: 28x28 (2D matrix)\n",
        "After reshaping: 784 (1D array)\n",
        "2. Normalize Pixel Values\n",
        "* The division by 255.0 scales the pixel values to the range [0, 1].\n",
        "* Pixel values in the MNIST dataset range from 0 to 255.\n",
        "* Neural networks perform better when input values are normalized because it helps gradients converge faster during training."
      ],
      "metadata": {
        "id": "VpBOZ1VIsF77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1,28*28)/255.0\n",
        "x_test = x_test.reshape(-1,28*28)/255.0"
      ],
      "metadata": {
        "id": "x2traLMDivt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgCiYvBps2XY",
        "outputId": "99722580-97f1-4643-c652-34bde0b54d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "pM73iAtQiPXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeA01YUestkX",
        "outputId": "de001ab0-4871-424d-d148-80d7ffc169f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Sequential API :\n",
        "The Sequential API is a simple and straightforward way to build models layer-by-layer, where each layer has exactly one input tensor and one output tensor. It’s best suited for linear stacks of layers without any branching, skipping, or multiple inputs/outputs.\n",
        "2. The Functional API :\n",
        "The Functional API is more flexible and powerful. It allows you to define models as directed acyclic graphs (DAGs) of layers. It supports complex architectures like models with multiple inputs, multiple outputs, shared layers, or skip connections."
      ],
      "metadata": {
        "id": "WOzwylkDEMKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#functional api -- multiple inputs and outputs\n",
        "input = keras.Input(shape=(784,))  #shape=(784,) specifies that the input to the model is a vector of length 784.\n",
        "x = layers.Dense(512,activation='relu')(input)\n",
        "x = layers.Dense(256,activation='relu')(x)\n",
        "x = layers.Dense(128,activation='relu')(x)\n",
        "outputs = layers.Dense(10,activation='softmax')(x)\n",
        "model=keras.Model(inputs=input,outputs=outputs) # input if more then 1 toh list hogi input and output bhi list hogi if >1"
      ],
      "metadata": {
        "id": "DyemSnlCi94J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "GtTAg-90kMMA",
        "outputId": "66a50e31-1ed9-4098-b44b-1b64a6b7b6b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m401,920\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m567,434\u001b[0m (2.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">567,434</span> (2.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m567,434\u001b[0m (2.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">567,434</span> (2.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The compile() method is used to configure the model for training. It specifies:\n",
        "\n",
        "* The optimizer: How the model updates its weights during training (Adam with a learning rate of 0.0003 in this case).\n",
        "* The loss function: How the model measures its error (SparseCategoricalCrossentropy for multi-class classification with integer labels).\n",
        "* The metrics: What performance metrics to track during training and evaluation."
      ],
      "metadata": {
        "id": "xLC7EfbILGjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(3e-4),loss=keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "w4W_J-urkNRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. x_train:\n",
        "This is the input training data. In this case, x_train contains the input features for the model (e.g., flattened MNIST images with shape (num_samples, 784)). Each row represents one training sample.\n",
        "2. y_train:\n",
        "This is the target labels (or ground truth) corresponding to x_train. It should match the number of samples in x_train (e.g., if x_train has 60,000 samples, y_train must also have 60,000 labels).\n",
        "Example: For MNIST, y_train would be a vector of class labels (e.g., [0, 1, 2, ..., 9]).\n",
        "3. batch_size=64\n",
        "This specifies the number of samples the model processes before updating its weight.\n",
        "* What is a batch? -- Instead of processing all training samples at once, the data is split into smaller \"batches.\" The model updates its weights after processing each batch.\n",
        "* Batch Size: 64 means the model will process 64 samples at a time before updating weights.\n",
        "* Why Batch Processing? --\n",
        "It reduces memory usage, as only a small subset of the data is loaded into memory at once.\n",
        "It improves training efficiency because weight updates occur more frequently than with full-batch training.\n",
        "\n",
        "4. epochs=10\n",
        "This specifies the number of complete passes through the training dataset:\n",
        "\n",
        "* 1 Epoch: The model processes all the training samples once (split into batches).\n",
        "* 10 Epochs: The model processes the entire dataset 10 times. Each pass allows the model to learn and adjust weights further.\n",
        "* More epochs can lead to better training, but excessive epochs may lead to overfitting.\n",
        "\n",
        "5. verbose=1\n",
        "This controls the level of detail printed during training:\n",
        "\n",
        "* 0: No output (silent mode).\n",
        "* 1: Displays a progress bar for each epoch, along with training metrics like loss and accuracy.\n",
        "* 2: Displays one line per epoch with the metrics, without the progress bar.\n",
        "--------\n",
        "\n",
        "* 938/938: Indicates the number of batches (for example, if there are 60,000 samples with batch size 64, there are 60000/64 = 938 batches).\n",
        "* loss: Training loss on the current batch/epoch.\n",
        "* accuracy: Training accuracy for the current batch/epoch.\n",
        "* val_loss: Validation loss after each epoch.\n",
        "* val_accuracy: Validation accuracy after each epoch."
      ],
      "metadata": {
        "id": "GaAq6CHfRgXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=1,validation_data=(x_val,y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5FdTGa_kuqq",
        "outputId": "3c456011-2ea4-46dd-a560-6393b1e8ba0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.5793 - val_accuracy: 0.9571 - val_loss: 0.1489\n",
            "Epoch 2/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.1231 - val_accuracy: 0.9679 - val_loss: 0.1056\n",
            "Epoch 3/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0749 - val_accuracy: 0.9729 - val_loss: 0.0887\n",
            "Epoch 4/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0476 - val_accuracy: 0.9762 - val_loss: 0.0782\n",
            "Epoch 5/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0329 - val_accuracy: 0.9778 - val_loss: 0.0763\n",
            "Epoch 6/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0256 - val_accuracy: 0.9745 - val_loss: 0.0862\n",
            "Epoch 7/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0192 - val_accuracy: 0.9753 - val_loss: 0.0902\n",
            "Epoch 8/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0139 - val_accuracy: 0.9712 - val_loss: 0.0998\n",
            "Epoch 9/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0122 - val_accuracy: 0.9768 - val_loss: 0.1008\n",
            "Epoch 10/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0114 - val_accuracy: 0.9793 - val_loss: 0.0903\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa76c10a710>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subclassing 2 function -- init (to initialize the architecture of nn ) and forward (how your forward propagation will take place)\n",
        "class Model(keras.Model):  # base class - keras.model -- inherits all property of keras.model\n",
        "  def __init__(self):\n",
        "    super(Model,self).__init__ ()  # initialize all parameters of parent class -- constructor --- how weights are computed, how back prop is taking place, yeh saara inherit hota h\n",
        "    self.dense1 = layers.Dense(512,activation='relu')\n",
        "    self.dense2 = layers.Dense(256,activation='relu')\n",
        "    self.dense3 = layers.Dense(128,activation='relu')\n",
        "    self.out = layers.Dense(10,activation='softmax')   # output as a name mat use karna keyword h woh\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    x = self.dense2(x)\n",
        "    x = self.dense3(x)\n",
        "    x = self.out(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "gOwOJL0Ek51V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Model()"
      ],
      "metadata": {
        "id": "SBdwkrLgoXBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(3e-4),loss=keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
        "model.fit(x_train,y_train,batch_size=64,epochs=10,verbose=1,validation_data=(x_val,y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti5hMTAWov_e",
        "outputId": "e612ea42-fc18-48ef-a25b-75aa5d3a51fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9964 - loss: 0.0104 - val_accuracy: 0.9808 - val_loss: 0.0788\n",
            "Epoch 2/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0066 - val_accuracy: 0.9799 - val_loss: 0.0907\n",
            "Epoch 3/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9970 - loss: 0.0096 - val_accuracy: 0.9804 - val_loss: 0.0894\n",
            "Epoch 4/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9794 - val_loss: 0.0924\n",
            "Epoch 5/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0060 - val_accuracy: 0.9798 - val_loss: 0.0945\n",
            "Epoch 6/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9826 - val_loss: 0.0867\n",
            "Epoch 7/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9987 - loss: 0.0033 - val_accuracy: 0.9847 - val_loss: 0.0858\n",
            "Epoch 8/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9808 - val_loss: 0.0965\n",
            "Epoch 9/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.9811 - val_loss: 0.1001\n",
            "Epoch 10/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 0.9822 - val_loss: 0.0913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x796569177210>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.evaluate(x_test, y_test, batch_size=32, verbose=2) -- for evaluation"
      ],
      "metadata": {
        "id": "28CiSurGpjZZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}